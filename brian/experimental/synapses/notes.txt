Notes
=====
Synapses variables
------------------
* presynaptic i -> synapse indexes
* presynaptic i -> delay
* synapse -> variables (w)
* synapse -> presynaptic i (int32 or smaller, based on the size of the presynaptic group)
* synapse -> postsynaptic j
	These two are currently in existing_synapses
	All synaptic mappings are handled by a SparseStateVector (deals with multiple types)
	Maybe we don't need a StateVector (just dynamic arrays)

and for backpropagation (STDP):
* postsynaptic j -> synapse indexes
* postsynaptic j -> delay
(do we need synapse -> delay?)

Also
* presynaptic queue (pre_queue)
* postsynaptic queue
* presynaptic/postsynaptic code and namespace (pre_code,pre_namespace)

Data structure
--------------
Currently, synapses are pushed: there is no order (meaning synapse indexes for neuron i may not
be contiguous).
Operations to optimize:
* search
* insertion: push values (O(1))
* deletion (should it be allowed?)
	we use a mask for deleted synapses

There are also two mappings:
* presynaptic i -> synapse indexes (sorted by synapse index)
* postsynaptic j -> synapse indexes

Current search (i,j):
* get synapse indexes for pre i and post j
* calculate intersection
O(p) (p = number of synapses per neuron)

Alternative: use a hash table of synapses for each presynaptic neuron: synapse[i][j]

The structure must be dynamic.
Maybe we don't need to compress the structure.

Initialisation
--------------
Currently:
* parse model equations and create a state updater
* clean pre/post strings
* create variables (state vector)
* create and compile pre code
	pre code deals with v+=w (problem with repeated postsynaptic indexes)

Call
----
* Synapses object gets the synaptic events and apply the pre code
* Call state updater

StateVector
-----------
A state matrix for variables with different dtypes. 
ConstructionSparseStateVector -> StateVector.
ParameterVector = 1 row of a StateVector. Required for S.w[1,2].

Clock
-----
Currently, we initialize the object with the clock of the synaptic state
updater. At this time, it will not work if the clocks of the neuron groups are
different. However, it should be possible in principle (but more complex).

Event-driven updates
--------------------
A simple start would be to deal with 1D linear differential equations.
Steps:
1) identify isolated 1D linear differential equations in model,
2) remove them from the model string,
3) compute the update string,
4) insert at the beginning of pre and post.

Here is how to deal with 3) using sympy. Assuming RHS=a*x+b:
1) z=brian.optimiser.symbolic_eval(RHS)
2) z.coeff(Symbol('x')) -> a
3) z.subs(Symbol('x'),0) or z.coeff(1) -> b
4) str(...) for the string representation

For step 1):
1) Look for variable names that are defined by differential equations.
2) If there is only the one on the LHS, then this is a 1D equation.
3) Check linearity, either using sympy (I don't know what exactly), or
the utilities in inspection (is_affine; setting external variables to 0).

All this assumes that some parsing of the equations is already done.
For this, we will need to bypasse NeuronGroup.__init__.

Various notes
-------------
* We want to be able to use StateUpdater objects on the synaptic variables.
This means we need a view on a state matrix (only the floats).
We also need some of the methods that are in NeuronGroup.
* I decided to use signed rather than unsigned ints for indexes, because there
were some conversion problems.
