**********************************
Distributed function documentation
**********************************

A distributed function is defined from any function and allows to execute it 
transparently in parallel over several workers (multiple CPUs on a single machine
or several machines connected in a network).

Quick examples
==============

Quick example 1
---------------

The simplest way of using ``DistributedFunction`` is by defining a function which
accepts a single object (a number, a Numpy array or any other object) as an argument 
and returns a result. Using ``DistributedFunction`` allows to call this function in 
parallel over multiple CPUs/machines with several objects as arguments, and retrieving 
the result for each argument. By default, ``DistributedFunction`` uses all available CPUs
in the system.

In the following example which computes the inverse of two matrices, we assume that there 
are at least two CPUs in the system. Each CPU computes the inverse of a single matrix::
    
    # For Windows users, it is required that any code using this library is placed after
    # this line, otherwise the system will crash!
    if __name__ == '__main__':
        
        from numpy import eye
        from numpy.linalg import inv
        
        # Import the library to have access to the ``DistributedFunction`` class
        from distfun import *
        
        # We define the two matrices that are going to be inversed in parallel.
        A = 2*eye(3,3)
        B = 3*eye(3,3)
        
        # The first argument of ``DistributedFunction`` is the name of the function
        # that is being parallelized. This function must accept a single argument and returns a
        # single object. The optional argument ``max_cpu=n`` allows to limit the number
        # of CPUs that are going to be used by the parallelized function. Of course,
        # this has no effect if there are less than n CPUs available in the system.
        distinv = DistributedFunction(inv, max_cpu=2)
        
        # ``distinv`` is the parallelized version of ``inv`` : it is called by passing
        # a list of arguments. The list can be of any size. If there are more arguments
        # than workers, then each worker will process several arguments in series.
        # Here, if there are two available CPUs in the system, the first CPU inverses
        # A, the second inverses B. ``invA`` and ``invB`` contain the inverses of A and B.
        invA, invB = distinv([A,B])
        
Quick example 2
---------------

In this second example, we want to parallelize a function ``f`` that accepts any
D-long vector and returns a number. Very often, it is possible to vectorize
this function using Numpy matrices operations, in such a way that the vectorized function 
``fun`` takes a DxN matrix ``x`` as an argument, and returns a N-long vector. 
We have ``fun(x)[i] == f(x[:,i])``.
In this case, it becomes easy to parallelize this function over multiple 
CPUs/machines. The argument ``x`` is divided into D*K submatrices of approximate
equal size. Each worker calls ``fun`` with the corresponding submatrix,
and the manager pastes back the results of the workers in a transparent way.
The parallelization is then totally transparent to the user.

In the following example, the function ``f`` computes the sum of the components
of a D-long vector. The Numpy function ``sum`` can do this in a vectorized way :
if ``x`` is a DxN matrix, ``sum(x, axis=0)`` is an N-long vector containg 
the sum of the components of each column of ``x``. Therefore, this function
can be parallelized like this::

    from numpy import sum
    def fun(x):
        return sum(x, axis=0)
    
    if __name__ == '__main__':
        from numpy import ones
        from distfun import *
        
        dfun = DistributedFunction(fun)
        x = ones((5,4))
        y = dfun(x)
        print y

Here, if there are two CPUs in the system, each one will execute ``fun(subx)`` 
with ``subx`` being the left half of ``x`` for CPU 1, and the right half for 
CPU 2. ``y`` is therefore a N-long vector, and is stricly equivalent to
the result that would have been obtained with ``y=fun(x)``.

Detailled examples
==================

