'''
Notes:

The main problem for STDP does indeed appear to be the running of the STDP code
and not the get_past_values_seq method of RecentStateMonitor. So, code generation
and optimisation efforts should be focussed on the code in stdp.py.

Here is the code currently generated by stdp.py

------ no delays ---------

****** PRE **********
for _i in spikes:
    A_pre[_i]+=dA_pre
    w[_i,:]+=A_post
    w[_i,:]=clip(w[_i,:],0.000000,0.010000)
****** POST *********
for _i in spikes:
    A_post[_i]+=dA_post
    w[:,_i]+=A_pre
    w[:,_i]=clip(w[:,_i],0.000000,0.010000)
    
    
------- heterogeneous delays ------

****** PRE_IMMEDIATE **********
for _i in spikes:
    A_pre[_i]+=dA_pre

****** PRE_DELAYED **********
for _j, _i in enumerate(spikes):
    A_post__delayed = A_post__delayed_values_seq[_j]
    w[_i,:]+=A_post__delayed

    w[_i,:] = clip(w[_i,:], 0.000000, 0.010000)
****** POST *********
for _i in spikes:
    A_post[_i]+=dA_post
for _j, _i in enumerate(spikes):
    A_pre__delayed = A_pre__delayed_values_seq[_j]
    w[:,_i]+=A_pre__delayed

    w[:,_i] = clip(w[:,_i], 0.000000, 0.010000)


with some obvious speedups this should become (in Python):

------ no delays ---------

****** PRE **********
A_pre[spikes] += dA_pre
for _i in spikes:
    w[_i,:]+=A_post
    w[_i,:]=clip(w[_i,:],0.000000,0.010000)
****** POST *********
A_post[spikes] += dA_post
for _i in spikes:
    w[:,_i]+=A_pre
    w[:,_i]=clip(w[:,_i],0.000000,0.010000)

For the general case, we can't do much better than that because:

* w[i,:]+=A_post has to wokr for dense, sparse and dynamic matrices
  - for dense it would be better to replace with
       w[spikes,:]+=A_post (you probably need to reshape though)
  - for sparse but not dynamic it could be done inline maybe
       asarray(w[i,:])+=A_post
  - but this only works for row access, not for column access!
  - for dynamic, there's no getting around it
* w[i,:]=clip(...) can be made inline for dense matrices, or for sparse
  but not dynamic, but w[:,i] only for dense.

A weave based clip(matrix, spikes, low, high) could significantly improve speed,
as the profiler suggests a decent amount of time is spent on clipping.

For a C++ based optimisation, can we avoid the for loop? In Connection.propagate
we don't have to worry about data references because we only have read access to
w, but we can't avoid it here. One option is the same as the Connection.propagate
solution: we have Python code that generates a list of rows/cols and then the
output of the STDP code would act on a second list, and then these values would
then be put back into the original data structure. But it's not clear that this
would be a huge speedup as it involves several stages.

Another option would be to paste pieces of C code together that correctly
preserve the references for the different data structures. Each piece of C code
would do its iteration, and produce a variable as a C++ reference for the
next piece of code. This requires a bit more thought to implement, but has
potentially high payoffs. It may also have high payoffs for ordinary
Connection.propagate as then the entire routine would be in C++ and you could
avoid the Python list comprehension and creation of data structures that we
have at the moment.

'''

from brian import *
from scipy import weave

